{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICAT3260 Machine Learning for Computer Vision\n",
    "## Exercise Set 8 (4.11.2025)\n",
    "\n",
    "**Goal:** Combine feature detection (Ex6), homogeneous coordinates (Ex7), and image transforms (Theme 8) for image stitching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Translation with Homogeneous Coordinates\n",
    "**Task:** Calculate the 3x3 translation matrix $T_1$ to move point $(10, 20)$ to $(30, 25)$.\n",
    "\n",
    "**Solution:**\n",
    "Translation vector: $\\Delta x = 30-10=20$, $\\Delta y = 25-20=5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original point\n",
    "p1 = np.array([10, 20, 1])\n",
    "\n",
    "# Desired point (30, 25) -> Translation d = (20, 5)\n",
    "tx, ty = 20, 5\n",
    "\n",
    "T1 = np.array([\n",
    "    [1, 0, tx],\n",
    "    [0, 1, ty],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "print(\"T1 (Translation Matrix):\\n\", T1)\n",
    "print(\"Verified Translation:\", T1 @ p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Rotation with Homogeneous Coordinates\n",
    "**Task:** Calculate the 3x3 rotation matrix $T_2$ to rotate point $(10, 20)$ by 30 degrees clockwise.\n",
    "\n",
    "**Solution:**\n",
    "Clockwise rotation by angle $\\theta$ corresponds to rotating by $-\\theta$ in standard mathematical convention (counter-clockwise is positive).\n",
    "Angle: $\\theta = -30^{\\circ}$ ($30^{\\circ}$ clockwise).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cos(-30) = Cos(30), Sin(-30) = -Sin(30)\n",
    "theta_deg = -30\n",
    "theta = np.deg2rad(theta_deg)\n",
    "\n",
    "c, s = np.cos(theta), np.sin(theta)\n",
    "\n",
    "T2 = np.array([\n",
    "    [c, -s, 0],\n",
    "    [s,  c, 0],\n",
    "    [0,  0, 1]\n",
    "])\n",
    "\n",
    "print(f\"T2 (Rotation Matrix for {theta_deg} deg):\\n\", T2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Composition of Transformations\n",
    "**Task:** Compose $T_1$ and $T_2$ and calculate coordinates for $(10, 20)$.\n",
    "*Note:* The order isn't explicitly defined, but transformation usually implies applying one then the other. If we interpret 'compose matrices T1 and T2' we usually do $T_{composed} = T_2 \\cdot T_1$ (Translate then Rotate) or $T_1 \\cdot T_2$ (Rotate then Translate). Let's assume Rotate then Translate ($T_1 \\cdot T_2$) is a common operation (rotate object then move it), or standard composition. Let's calculate $T_{final} = T_1 @ T_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order: Rotate first, then Translate usually (T1 @ T2)\n",
    "# p_new = T1 * (T2 * p)\n",
    "T_composed = T1 @ T2\n",
    "\n",
    "print(\"Composed Matrix (T1 @ T2):\\n\", T_composed)\n",
    "\n",
    "p_original = np.array([10, 20, 1])\n",
    "p_final = T_composed @ p_original\n",
    "\n",
    "# Normalize (though w should be 1)\n",
    "p_final_coords = p_final[:2] / p_final[2]\n",
    "\n",
    "print(f\"Original: {p_original[:2]}\")\n",
    "print(f\"Transformed: {p_final_coords}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SIFT Matching & Homography with RANSAC\n",
    "**Task:** Use SIFT to find features between two images and RANSAC to filter matches.\n",
    "**Setup:** Ensure `left.png` and `right.png` are in the directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Images\n",
    "img1 = cv.imread('left.png') # Query (ref)\n",
    "img2 = cv.imread('right.png') # Train (rot)\n",
    "\n",
    "if img1 is None or img2 is None:\n",
    "    print(\"Error: Images not found! Please upload 'left.png' and 'right.png'.\")\n",
    "else:\n",
    "    # Convert to RGB for display\n",
    "    img1_rgb = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "    img2_rgb = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    # 1. SIFT Detector\n",
    "    sift = cv.SIFT_create()\n",
    "\n",
    "    # 2. Keypoints & Descriptors\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # 3. Matching (BFMatcher)\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Lowe's Ratio Test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # 4. RANSAC for Homography\n",
    "    # Need at least 4 matches\n",
    "    if len(good_matches) > 4:\n",
    "        # Extract points\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Tune RANSAC threshold (e.g., 5.0)\n",
    "        ransac_threshold = 5.0 \n",
    "        H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, ransac_threshold)\n",
    "        \n",
    "        # Select inliers\n",
    "        matches_mask = mask.ravel().tolist()\n",
    "        inlier_matches = [m for i, m in enumerate(good_matches) if matches_mask[i]]\n",
    "\n",
    "        print(f\"RANSAC Threshold: {ransac_threshold}\")\n",
    "        print(f\"Original Matches: {len(good_matches)}\")\n",
    "        print(f\"Inlier Matches: {len(inlier_matches)}\")\n",
    "\n",
    "        # Draw Inliers\n",
    "        draw_params = dict(matchColor=(0, 255, 0), singlePointColor=None, matchesMask=matches_mask, flags=2)\n",
    "        img_matches = cv.drawMatches(img1_rgb, kp1, img2_rgb, kp2, good_matches, None, **draw_params)\n",
    "        \n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.imshow(img_matches)\n",
    "        plt.title(f\"Inlier Matches (Thresh={ransac_threshold})\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough matches found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Image Warping\n",
    "**Task:** Warp `img1` to coordinates of `img2`. \n",
    "*Note:* `cv.findHomography(src, dst)` computes mapping from src to dst. If we want to align `img1` (left) onto `img2` (right) or vice versa, we must be careful with source/destination points. \n",
    "Usually we warp the 'right' image to the 'left' image (ref). \n",
    "Let's assume we align `img2` (right) -> `img1` (left). \n",
    "Code below re-computes H for `img2 -> img1` mapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for warping img2 (right) matching img1 (left)\n",
    "# src: img2 (right), dst: img1 (left)\n",
    "if len(good_matches) > 4:\n",
    "    # Notice the order swap for src/dst to warp img2 -> img1\n",
    "    src_pts_img2 = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts_img1 = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    H, mask = cv.findHomography(src_pts_img2, dst_pts_img1, cv.RANSAC, 5.0)\n",
    "\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    # Warp img2 using H\n",
    "    warped_img2 = cv.warpPerspective(img2, H, (w1, h1))\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(cv.cvtColor(warped_img2, cv.COLOR_BGR2RGB))\n",
    "    plt.title(\"Warped Image 2 (Aligned to Img1 Frame)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Simple Overlay\n",
    "**Task:** Visually check alignment using `cv.addWeighted`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay\n",
    "overlay = cv.addWeighted(img1, 0.5, warped_img2, 0.5, 0)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(cv.cvtColor(overlay, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Overlay Result\")\n",
    "plt.show()\n",
    "\n",
    "# Q: What does cv.addWeighted do?\n",
    "# A: It calculates weighted sum: dst = src1*alpha + src2*beta + gamma\n",
    "# Here it blends 50% of img1 and 50% of warped_img2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) (Optional) Full Panorama Stitching\n",
    "**Task:** Create a canvas large enough for both images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate size of the Stitching canvas\n",
    "h1, w1 = img1.shape[:2]\n",
    "h2, w2 = img2.shape[:2]\n",
    "\n",
    "# Get corners of img2\n",
    "pts_img2 = np.float32([[0,0], [0,h2], [w2,h2], [w2,0]]).reshape(-1,1,2)\n",
    "\n",
    "# Transform corners to img1 coordinate space\n",
    "pts_img2_transformed = cv.perspectiveTransform(pts_img2, H)\n",
    "\n",
    "# Concatenate with img1 corners to find bounding box\n",
    "pts_img1 = np.float32([[0,0], [0,h1], [w1,h1], [w1,0]]).reshape(-1,1,2)\n",
    "all_points = np.concatenate((pts_img1, pts_img2_transformed), axis=0)\n",
    "\n",
    "# Find min/max x, y\n",
    "[xmin, ymin] = np.int32(all_points.min(axis=0).ravel() - 0.5)\n",
    "[xmax, ymax] = np.int32(all_points.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "# Calculate translation matrix H_translation to shift everything to positive coordinates\n",
    "translation_dist = [-xmin, -ymin]\n",
    "H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0,0,1]])\n",
    "\n",
    "# Full Homography\n",
    "H_full = H_translation @ H\n",
    "\n",
    "# Size of new canvas\n",
    "canvas_w = xmax - xmin\n",
    "canvas_h = ymax - ymin\n",
    "\n",
    "# Warp img2 to new canvas\n",
    "warped_img2_full = cv.warpPerspective(img2, H_full, (canvas_w, canvas_h))\n",
    "\n",
    "# Paste img1 onto new canvas (taking translation into account)\n",
    "# img1 is identity transformed, just translated\n",
    "# We can use warped_img2_full as base and just overwrite the img1 region?\n",
    "# No, we should blend or overwrite gracefully.\n",
    "# Simplest: copy img1 into the translated position\n",
    "y_start, x_start = translation_dist[1], translation_dist[0]\n",
    "warped_img2_full[y_start:y_start+h1, x_start:x_start+w1] = img1\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(cv.cvtColor(warped_img2_full, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Full Panorama\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}