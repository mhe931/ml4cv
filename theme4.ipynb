{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad50fa47",
   "metadata": {},
   "source": [
    "# Theme 4: Convolutional Neural Networks (CNN)\n",
    "\n",
    "In this exercise set we use as a basis the same dataset and code as in Theme 3, but this time we extend it to a Convolutional Neural Network (CNN) for classification.\n",
    "\n",
    "## Goals\n",
    "1.  **CNN Basics**: Build a simple CNN with Strided Convolutions.\n",
    "2.  **Pooling**: Understand the effect of MaxPooling.\n",
    "3.  **Visualization**: Visualize learned kernels.\n",
    "4.  **Batch Normalization**: Improve training stability.\n",
    "5.  **Regularization**: Apply L2 regularization to CNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82228ea5",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "We add `Conv2D`, `MaxPooling2D`, and `BatchNormalization` to our toolkit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf279c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155bedaa",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "In Deep Learning, data plumbing is often 80% of the work. We need robust functions to:\n",
    "- **Load Labels**: Read class IDs from text files.\n",
    "- **Load Images**: Read image files into NumPy arrays.\n",
    "- **Normalize**: Scale pixel values to a small range (e.g., -1 to 1 or 0 to 1) to help the optimizer converge.\n",
    "- **Split**: Separate data into Testing and Validation sets to ensure we don't cheat by optimizing on our test data.\n",
    "\n",
    "*Self-Learning Note*: Notice `normalize_dataset`. It shifts data to be 0-centered (approx) by subtracting 128 and dividing by 128. This helps gradient descent steps be more uniform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531dd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "def load_labels(filename):\n",
    "    with open(filename,'r') as file:\n",
    "       li = file.readlines()\n",
    "    label_count = len(li)\n",
    "    labels = np.empty((label_count,1), dtype='int')\n",
    "    i = 0\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            labels[i] = int(line.replace(\"\\n\", \"\"))\n",
    "            i = i + 1\n",
    "    return labels\n",
    "\n",
    "def load_images(folder, image_count, image_size):\n",
    "    array_shape = (image_count, image_size[0], image_size[1], image_size[2])\n",
    "    imageset = np.empty(array_shape, dtype='float')\n",
    "    for i in range(0,image_count):\n",
    "        fname = os.path.join(folder, 'image_' + \"{:04d}\".format(i) + '.png')\n",
    "        if not os.path.exists(fname):\n",
    "             print(f\"Warning: File {fname} not found.\")\n",
    "             continue\n",
    "        image = Image.open(fname)\n",
    "        imageset[i] = np.asarray(image)\n",
    "    return imageset\n",
    "\n",
    "def normalize_dataset(sampled_images):\n",
    "    # Scale to range [-1, 1] approx\n",
    "    sampled_images = (sampled_images.astype('float32')-128) / 128\n",
    "    return sampled_images\n",
    "\n",
    "def split_test_val(data, splitpoint):\n",
    "    # Returns (Tail, Head) - careful with indices!\n",
    "    return data[splitpoint:], data[:splitpoint]\n",
    "\n",
    "def create_model(input_shape, dense_size, classes, l2_reg=None):\n",
    "    x = Input(shape=(input_shape))\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    if l2_reg:\n",
    "        y = Dense(classes, activation='softmax', name='dense_layer', kernel_regularizer=l2_reg)(y)\n",
    "    else:\n",
    "        y = Dense(classes, activation='softmax', name='dense_layer')(y)\n",
    "        \n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    return model\n",
    "\n",
    "def create_model_2_layers(input_shape, dense_size, classes):\n",
    "    x = Input(shape=(input_shape))\n",
    "    y = Flatten()(x)\n",
    "    # Task 7: 2nd dense layer usually adds 'depth' allowing complex features\n",
    "    y = Dense(dense_size, activation='relu', name='dense_layer_1')(y)\n",
    "    y = Dense(classes, activation='softmax', name='dense_layer_out')(y)\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    return model\n",
    "\n",
    "def visualize_weights(model, layer_name, title, filename):\n",
    "    try:\n",
    "        weights, biases = model.get_layer(layer_name).get_weights()\n",
    "    except ValueError:\n",
    "        print(f\"Layer {layer_name} not found or has no weights\")\n",
    "        return\n",
    "\n",
    "    # Weights shape: (InputDim, Units) -> (3072, 10)\n",
    "    input_shape = (32, 32, 3)\n",
    "    n_units = weights.shape[1]\n",
    "    \n",
    "    # We want to show the weights for each class (unit)\n",
    "    rows = 2\n",
    "    cols = 5 \n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i >= n_units:\n",
    "            break\n",
    "\n",
    "        weight_vector = weights[:, i]\n",
    "        # Reshape: (3072,) -> (32, 32, 3)\n",
    "        weight_image = weight_vector.reshape(input_shape)\n",
    "\n",
    "        # Normalize to 0-1 for display\n",
    "        min_val = weight_image.min()\n",
    "        max_val = weight_image.max()\n",
    "        weight_image = (weight_image - min_val) / (max_val - min_val + 1e-5)\n",
    "\n",
    "        ax.imshow(weight_image)\n",
    "        ax.set_title(f'Class {i}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show() # Changed from savefig to show for notebook\n",
    "    print(f\"Visualization generated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2494807",
   "metadata": {},
   "source": [
    "## 3. Loading Data\n",
    "\n",
    "We load the CIFAR-10 subset.\n",
    "We assume the `resources` folder is in the current working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388417d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data ---\n",
      "Data Loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Loading Data ---\")\n",
    "base_res = 'resources' # Assumed relative to CWD\n",
    "if not os.path.exists(base_res):\n",
    "    print(f\"ERROR: '{base_res}' directory not found. Please ensure you are in the correct directory.\")\n",
    "else:\n",
    "    # 1. Load Labels\n",
    "    y_train = load_labels(os.path.join(base_res, 'training/labels.csv'))\n",
    "    \n",
    "    # 2. Load Images (based on how many labels we have)\n",
    "    x_train_raw = load_images(os.path.join(base_res, 'training'), len(y_train), (32,32,3))\n",
    "    \n",
    "    Y_test = load_labels(os.path.join(base_res, 'testing/labels.csv'))\n",
    "    X_test_raw = load_images(os.path.join(base_res, 'testing'), len(Y_test), (32,32,3))\n",
    "\n",
    "    print(\"Data Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bca26",
   "metadata": {},
   "source": [
    "## 4. Normalization & Splitting\n",
    "\n",
    "**Normalization**: Raw pixel values are 0-255. Neural networks prefer inputs near 0 with unit variance. We subtract 128 and divide by 128.\n",
    "\n",
    "**Splitting**: We split the 'Test' set folder into a true 'Test' set and a 'Validation' set.\n",
    "- **Validation**: Used during training to check progress.\n",
    "- **Test**: Used ONLY at the very end to report final performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be72ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (10000, 32, 32, 3)\n",
      "Validation set: (2000, 32, 32, 3)\n",
      "Test set: (3000, 32, 32, 3)\n",
      "Classes: 10\n"
     ]
    }
   ],
   "source": [
    "x_train = normalize_dataset(x_train_raw)\n",
    "X_test = normalize_dataset(X_test_raw)\n",
    "\n",
    "# Splitting logic from original script\n",
    "# index 0 to 2000 -> Validation\n",
    "# index 2000 to End -> Test\n",
    "splitpoint = 2000\n",
    "x_test, x_val = split_test_val(X_test, splitpoint)\n",
    "y_test, y_val = split_test_val(Y_test, splitpoint)\n",
    "\n",
    "class_count = len(np.unique(y_train))\n",
    "dims = (32, 32, 3)\n",
    "dense_sz = 100\n",
    "\n",
    "print(f\"Training set: {x_train.shape}\")\n",
    "print(f\"Validation set: {x_val.shape}\")\n",
    "print(f\"Test set: {x_test.shape}\")\n",
    "print(f\"Classes: {class_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a980c476",
   "metadata": {},
   "source": [
    "## 2. First CNN: Strided Convolutions\n",
    "\n",
    "\n",
    "\n",
    "Instead of flattening the image immediately, we use `Conv2D` layers to extract spatial features.\n",
    "\n",
    "We use `strides=2` to downsample the efficient spatial dimensions instead of pooling.\n",
    "\n",
    "\n",
    "\n",
    "**Architecture**:\n",
    "\n",
    "1.  Input (32, 32, 3)\n",
    "\n",
    "2.  Conv2D (32 filters, 3x3, stride=2, padding='same')\n",
    "\n",
    "3.  Conv2D (64 filters, 3x3, stride=2, padding='same')\n",
    "\n",
    "4.  Flatten\n",
    "\n",
    "5.  Dense (100)\n",
    "\n",
    "6.  Dense (10 classses)\n",
    "\n",
    "\n",
    "\n",
    "**Hyperparameters**:\n",
    "\n",
    "-   Epochs: 12\n",
    "\n",
    "-   Learning Rate: 3e-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a8c3c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Strided CNN ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">409,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m409,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">430,102</span> (1.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m430,102\u001b[0m (1.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">430,102</span> (1.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m430,102\u001b[0m (1.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "313/313 - 3s - 10ms/step - accuracy: 0.3693 - loss: 1.7940 - val_accuracy: 0.4385 - val_loss: 1.5682\n",
      "Epoch 2/12\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.5086 - loss: 1.4080 - val_accuracy: 0.5055 - val_loss: 1.4187\n",
      "Epoch 3/12\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.5736 - loss: 1.2218 - val_accuracy: 0.5065 - val_loss: 1.4096\n",
      "Epoch 4/12\n",
      "313/313 - 1s - 5ms/step - accuracy: 0.6373 - loss: 1.0693 - val_accuracy: 0.5290 - val_loss: 1.3215\n",
      "Epoch 5/12\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.6849 - loss: 0.9339 - val_accuracy: 0.5225 - val_loss: 1.3575\n",
      "Epoch 6/12\n",
      "313/313 - 1s - 5ms/step - accuracy: 0.7283 - loss: 0.8105 - val_accuracy: 0.5350 - val_loss: 1.3444\n",
      "Epoch 7/12\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.7717 - loss: 0.6934 - val_accuracy: 0.5425 - val_loss: 1.3690\n",
      "Epoch 8/12\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.8231 - loss: 0.5717 - val_accuracy: 0.5320 - val_loss: 1.4926\n",
      "Epoch 9/12\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.8530 - loss: 0.4864 - val_accuracy: 0.5355 - val_loss: 1.4595\n",
      "Epoch 10/12\n",
      "313/313 - 1s - 5ms/step - accuracy: 0.8910 - loss: 0.3828 - val_accuracy: 0.5135 - val_loss: 1.6274\n",
      "Epoch 11/12\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9238 - loss: 0.2953 - val_accuracy: 0.5310 - val_loss: 1.6520\n",
      "Epoch 12/12\n",
      "313/313 - 1s - 4ms/step - accuracy: 0.9431 - loss: 0.2340 - val_accuracy: 0.5405 - val_loss: 1.7344\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_strided(input_shape, dense_size, classes):\n",
    "\n",
    "    kernel_sz = (3, 3)\n",
    "\n",
    "    x = Input(shape=input_shape)\n",
    "\n",
    "    # 1st Conv Block\n",
    "\n",
    "    y = Conv2D(filters=32, kernel_size=kernel_sz, strides=2, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 2nd Conv Block\n",
    "\n",
    "    y = Conv2D(filters=64, kernel_size=kernel_sz, strides=2, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal')(y)\n",
    "\n",
    "    \n",
    "\n",
    "    y = Flatten()(y)\n",
    "\n",
    "    y = Dense(dense_size, activation='relu')(y)\n",
    "\n",
    "    y = Dense(classes, activation='softmax')(y)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- Training Strided CNN ---\")\n",
    "\n",
    "model_stride = create_cnn_strided(dims, dense_sz, class_count)\n",
    "\n",
    "model_stride.compile(loss='sparse_categorical_crossentropy', \n",
    "\n",
    "                     optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4), \n",
    "\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "model_stride.summary()\n",
    "\n",
    "\n",
    "\n",
    "history_stride = model_stride.fit(x_train, y_train, epochs=12, validation_data=(x_val, y_val), verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea4592",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "\n",
    "\n",
    "Compare the test accuracy with the Linear Network from Theme 3 (approx. 35-40%).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2873c626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (Strided CNN): 0.5383\n"
     ]
    }
   ],
   "source": [
    "score = model_stride.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test accuracy (Strided CNN): {score[1]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e446b",
   "metadata": {},
   "source": [
    "## 4. CNN with MaxPooling\n",
    "\n",
    "\n",
    "\n",
    "Now we switch to `strides=1` (no downsampling in convolution) and add explicit `MaxPooling2D` layers to reduce dimensions.\n",
    "\n",
    "\n",
    "\n",
    "**Architecture Change**:\n",
    "\n",
    "-   Conv2D (stride=1) -> MaxPooling2D\n",
    "\n",
    "-   Conv2D (stride=1) -> MaxPooling2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6dbec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training CNN with MaxPooling ---\n",
      "Epoch 1/12\n",
      "313/313 - 3s - 11ms/step - accuracy: 0.3856 - loss: 1.7341 - val_accuracy: 0.4560 - val_loss: 1.5147\n",
      "Epoch 2/12\n",
      "313/313 - 2s - 8ms/step - accuracy: 0.5355 - loss: 1.3368 - val_accuracy: 0.5230 - val_loss: 1.3351\n",
      "Epoch 3/12\n",
      "313/313 - 3s - 8ms/step - accuracy: 0.5966 - loss: 1.1645 - val_accuracy: 0.5490 - val_loss: 1.2342\n",
      "Epoch 4/12\n",
      "313/313 - 2s - 8ms/step - accuracy: 0.6517 - loss: 1.0242 - val_accuracy: 0.5645 - val_loss: 1.2014\n",
      "Epoch 5/12\n",
      "313/313 - 3s - 9ms/step - accuracy: 0.6846 - loss: 0.9240 - val_accuracy: 0.5850 - val_loss: 1.1658\n",
      "Epoch 6/12\n",
      "313/313 - 3s - 8ms/step - accuracy: 0.7133 - loss: 0.8424 - val_accuracy: 0.5955 - val_loss: 1.1509\n",
      "Epoch 7/12\n",
      "313/313 - 2s - 8ms/step - accuracy: 0.7497 - loss: 0.7496 - val_accuracy: 0.5910 - val_loss: 1.1393\n",
      "Epoch 8/12\n",
      "313/313 - 3s - 8ms/step - accuracy: 0.7755 - loss: 0.6686 - val_accuracy: 0.5955 - val_loss: 1.2019\n",
      "Epoch 9/12\n",
      "313/313 - 3s - 8ms/step - accuracy: 0.8047 - loss: 0.5994 - val_accuracy: 0.6005 - val_loss: 1.1674\n",
      "Epoch 10/12\n",
      "313/313 - 2s - 8ms/step - accuracy: 0.8321 - loss: 0.5242 - val_accuracy: 0.6050 - val_loss: 1.1991\n",
      "Epoch 11/12\n",
      "313/313 - 2s - 8ms/step - accuracy: 0.8557 - loss: 0.4584 - val_accuracy: 0.5855 - val_loss: 1.2809\n",
      "Epoch 12/12\n",
      "313/313 - 2s - 8ms/step - accuracy: 0.8781 - loss: 0.3977 - val_accuracy: 0.5970 - val_loss: 1.2549\n",
      "Test accuracy (Pooling CNN): 0.6097\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_pooling(input_shape, dense_size, classes):\n",
    "\n",
    "    kernel_sz = (3, 3)\n",
    "\n",
    "    x = Input(shape=input_shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # Block 1\n",
    "\n",
    "    y = Conv2D(filters=32, kernel_size=kernel_sz, strides=1, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    # Block 2\n",
    "\n",
    "    y = Conv2D(filters=64, kernel_size=kernel_sz, strides=1, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal')(y)\n",
    "\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    y = Flatten()(y)\n",
    "\n",
    "    y = Dense(dense_size, activation='relu')(y)\n",
    "\n",
    "    y = Dense(classes, activation='softmax')(y)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- Training CNN with MaxPooling ---\")\n",
    "\n",
    "model_pool = create_cnn_pooling(dims, dense_sz, class_count)\n",
    "\n",
    "model_pool.compile(loss='sparse_categorical_crossentropy', \n",
    "\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4), \n",
    "\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "history_pool = model_pool.fit(x_train, y_train, epochs=12, validation_data=(x_val, y_val), verbose=2)\n",
    "\n",
    "score_pool = model_pool.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test accuracy (Pooling CNN): {score_pool[1]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fb60a",
   "metadata": {},
   "source": [
    "## 5. Visualizing Kernels\n",
    "\n",
    "\n",
    "\n",
    "We visualize the 32 filters of the first layer.\n",
    "\n",
    "Since the input is RGB (3 channels), each filter is 3x3x3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65b83943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Conv2D Layer Weight Shape: (3, 3, 3, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_conv_weights(model, layer_index=1):\n",
    "\n",
    "    # Get weights\n",
    "\n",
    "    # Note: Keras layer indexing might vary. Usually Input is 0.\n",
    "\n",
    "    # We can also get by name if we named them, but let's grab the first Conv2D.\n",
    "\n",
    "    conv_layers = [l for l in model.layers if isinstance(l, Conv2D)]\n",
    "\n",
    "    if not conv_layers:\n",
    "\n",
    "        print(\"No Conv2D layers found.\")\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "\n",
    "    target_layer = conv_layers[0]\n",
    "\n",
    "    weights = target_layer.get_weights()[0] # [0] is weights, [1] is biases\n",
    "\n",
    "    print(f\"First Conv2D Layer Weight Shape: {weights.shape}\") \n",
    "\n",
    "    # Shape is (KernelH, KernelW, InputChannels, Filters) e.g. (3, 3, 3, 32)\n",
    "\n",
    "    \n",
    "\n",
    "    n_filters = weights.shape[3]\n",
    "\n",
    "    \n",
    "\n",
    "    # Setup plot\n",
    "\n",
    "    cols = 8\n",
    "\n",
    "    rows = np.ceil(n_filters / cols).astype(int)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, rows*1.5))\n",
    "\n",
    "    \n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        if i >= n_filters:\n",
    "\n",
    "            break\n",
    "\n",
    "        \n",
    "\n",
    "        # Get the filter: (3, 3, 3)\n",
    "\n",
    "        f = weights[:, :, :, i]\n",
    "\n",
    "        \n",
    "\n",
    "        # Normalize to 0-1 for display\n",
    "\n",
    "        f_min, f_max = f.min(), f.max()\n",
    "\n",
    "        f_disp = (f - f_min) / (f_max - f_min + 1e-5)\n",
    "\n",
    "        \n",
    "\n",
    "        ax.imshow(f_disp, interpolation='nearest')\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "        ax.set_title(f'#{i}')\n",
    "\n",
    "        \n",
    "\n",
    "    plt.suptitle(f\"Kernels of {target_layer.name}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "visualize_conv_weights(model_pool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682036d",
   "metadata": {},
   "source": [
    "## 6. Memory Usage\n",
    "\n",
    "\n",
    "\n",
    "**Parameter Count**:\n",
    "\n",
    "-   Conv2D parameters = `(kernel_h * kernel_w * input_channels + 1) * filters`\n",
    "\n",
    "-   Dense parameters = `(input_units + 1) * output_units`\n",
    "\n",
    "\n",
    "\n",
    "**Activation Memory** (Forward Pass):\n",
    "\n",
    "-   Layer Output Bytes = `Height * Width * Filters * 4 bytes (float32)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75815aac",
   "metadata": {},
   "source": [
    "## 7. Batch Normalization\n",
    "\n",
    "\n",
    "\n",
    "We add `BatchNormalization()` after each `Conv2D` and `Dense` layer to normalize activation distributions.\n",
    "\n",
    "This often allows higher learning rates and faster convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb396941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_bn(input_shape, dense_size, classes):\n",
    "\n",
    "    kernel_sz = (3, 3)\n",
    "\n",
    "    x = Input(shape=input_shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # Block 1\n",
    "\n",
    "    y = Conv2D(filters=32, kernel_size=kernel_sz, strides=1, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    # Block 2\n",
    "\n",
    "    y = Conv2D(filters=64, kernel_size=kernel_sz, strides=1, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal')(y)\n",
    "\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    y = Flatten()(y)\n",
    "\n",
    "    y = Dense(dense_size, activation='relu')(y)\n",
    "\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    y = Dense(classes, activation='softmax')(y)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- Training CNN with BN ---\")\n",
    "\n",
    "model_bn = create_cnn_bn(dims, dense_sz, class_count)\n",
    "\n",
    "model_bn.compile(loss='sparse_categorical_crossentropy', \n",
    "\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4), \n",
    "\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "history_bn = model_bn.fit(x_train, y_train, epochs=12, validation_data=(x_val, y_val), verbose=2)\n",
    "\n",
    "score_bn = model_bn.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test accuracy (BN): {score_bn[1]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe78af1",
   "metadata": {},
   "source": [
    "## 8. L2 Regularization\n",
    "\n",
    "\n",
    "\n",
    "We apply L2 regularization to weights to prevent overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_l2(input_shape, dense_size, classes, l2_strength=1e-4):\n",
    "\n",
    "    kernel_sz = (3, 3)\n",
    "\n",
    "    reg = regularizers.l2(l2_strength)\n",
    "\n",
    "    x = Input(shape=input_shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # Block 1\n",
    "\n",
    "    y = Conv2D(filters=32, kernel_size=kernel_sz, strides=1, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal', kernel_regularizer=reg)(x)\n",
    "\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    # Block 2\n",
    "\n",
    "    y = Conv2D(filters=64, kernel_size=kernel_sz, strides=1, activation='relu', \n",
    "\n",
    "               padding='same', kernel_initializer='he_normal', kernel_regularizer=reg)(y)\n",
    "\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    y = Flatten()(y)\n",
    "\n",
    "    y = Dense(dense_size, activation='relu', kernel_regularizer=reg)(y)\n",
    "\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    \n",
    "\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=reg)(y)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- Training CNN with L2 ---\")\n",
    "\n",
    "model_l2 = create_cnn_l2(dims, dense_sz, class_count, l2_strength=0.001)\n",
    "\n",
    "model_l2.compile(loss='sparse_categorical_crossentropy', \n",
    "\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4), \n",
    "\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "history_l2 = model_l2.fit(x_train, y_train, epochs=12, validation_data=(x_val, y_val), verbose=2)\n",
    "\n",
    "score_l2 = model_l2.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test accuracy (L2): {score_l2[1]:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
