{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d500267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Documents\\Projects\\ml4cv\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'testing/labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data[splitpoint:], data[:splitpoint]\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m Y_test = \u001b[43mload_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtesting/labels.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m X_test = load_images(\u001b[33m'\u001b[39m\u001b[33mtesting\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(Y_test), (\u001b[32m32\u001b[39m,\u001b[32m32\u001b[39m,\u001b[32m3\u001b[39m))\n\u001b[32m     48\u001b[39m y_train = load_labels(\u001b[33m'\u001b[39m\u001b[33mtraining/labels.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mload_labels\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_labels\u001b[39m(filename):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     19\u001b[39m        li = file.readlines()\n\u001b[32m     20\u001b[39m     label_count = \u001b[38;5;28mlen\u001b[39m(li)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Documents\\Projects\\ml4cv\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'testing/labels.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from PIL import Image\n",
    "\n",
    "def create_model(input_shape, dense_size, classes):\n",
    "    x = Input(shape=(input_shape))\n",
    "    y = Flatten()(x)\n",
    "    y = Dense(classes, activation='softmax', name='dense_layer')(y)\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    return model\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename,'r') as file:\n",
    "       li = file.readlines()\n",
    "    label_count = len(li)\n",
    "    labels = np.empty((label_count,1), dtype='int')\n",
    "    i = 0\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            labels[i] = int(line.replace(\"\\n\", \"\"))\n",
    "            i = i + 1\n",
    "    return labels\n",
    "\n",
    "def load_images(folder, image_count, image_size):\n",
    "    array_shape = (image_count, image_size[0], image_size[1], image_size[2])\n",
    "    imageset = np.empty(array_shape, dtype='float')\n",
    "    for i in range(0,image_count):\n",
    "        image = Image.open(folder + '/image_' + \"{:04d}\".format(i) + '.png')\n",
    "        imageset[i] = np.asarray(image)\n",
    "    return imageset\n",
    "\n",
    "def normalize_dataset(sampled_images):\n",
    "\tsampled_images = (sampled_images.astype('float32')-128) / 128\n",
    "\treturn sampled_images\n",
    "\n",
    "def split_test_val(data, splitpoint):\n",
    "    return data[splitpoint:], data[:splitpoint]\n",
    "\n",
    "########################################################################\n",
    "Y_test = load_labels('testing/labels.csv')\n",
    "X_test = load_images('testing', len(Y_test), (32,32,3))\n",
    "\n",
    "y_train = load_labels('training/labels.csv')\n",
    "x_train = load_images('training', len(y_train), (32,32,3))\n",
    "\n",
    "x_train = normalize_dataset(x_train)\n",
    "\n",
    "##### Test set preparation #####\n",
    "splitpoint = 2000\n",
    "X_test = normalize_dataset(X_test)\n",
    "x_test, x_val = split_test_val(X_test, splitpoint)\n",
    "y_test, y_val = split_test_val(Y_test, splitpoint)\n",
    "print('Validation set size', x_val.shape)\n",
    "print('Test set size:', x_test.shape)\n",
    "print('')\n",
    "\n",
    "class_count = len(np.unique(y_train))\n",
    "\n",
    "# define a neural network for training\n",
    "dims = (32, 32, 3)\n",
    "dense_sz = 100\n",
    "model = create_model(dims, dense_sz, class_count)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from PIL import Image\n",
    "\n",
    "# 1. DATA LOADING AND NORMALIZATION\n",
    "def load_images(folder, image_count, image_size):\n",
    "    array_shape = (image_count, image_size[0], image_size[1], image_size[2])\n",
    "    imageset = np.empty(array_shape, dtype='float')\n",
    "    for i in range(0, image_count):\n",
    "        # Open image and convert to numpy array\n",
    "        image = Image.open(f\"{folder}/image_{i:04d}.png\")\n",
    "        # DATA NORMALIZATION: Mapping [0, 255] to [-1, 1]\n",
    "        # Formula: (original - 128) / 128\n",
    "        imageset[i] = (np.asarray(image).astype('float') - 128.0) / 128.0\n",
    "    return imageset\n",
    "\n",
    "# 2. MODEL ARCHITECTURE (Linear / Dense Network)\n",
    "def create_model(input_shape, dense_size, classes, reg_strength=0.0):\n",
    "    x = Input(shape=input_shape)\n",
    "    \n",
    "    # Flatten converts (32, 32, 3) image to a 1D vector of 3072 values\n",
    "    y = Flatten()(x)\n",
    "    \n",
    "    # Hidden Layer with ReLU activation and L2 Regularization\n",
    "    # L2 helps prevent overfitting by penalizing large weights\n",
    "    y = Dense(dense_size, activation='relu', \n",
    "              kernel_regularizer=regularizers.l2(reg_strength))(y)\n",
    "    \n",
    "    # Output Layer: Softmax turns scores into probabilities for classification\n",
    "    y = Dense(classes, activation='softmax', name='output_layer')(y)\n",
    "    \n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    return model\n",
    "\n",
    "# 3. TRAINING CONFIGURATION\n",
    "model = create_model(input_shape=(32, 32, 3), dense_size=512, classes=10, reg_strength=0.03)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. WEIGHT VISUALIZATION (Main concept for the exam)\n",
    "# This snippet shows how to \"see\" what a neuron has learned\n",
    "weights, biases = model.get_layer('output_layer').get_weights()\n",
    "# Shape is (inputs, outputs) -> (3072, 10)\n",
    "# To visualize, we reshape the weights back to (32, 32, 3)\n",
    "weight_image = weights[:, 0].reshape(32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c078104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
